---
phase: 10-database-production-readiness
plan: 03
type: execute
wave: 2
depends_on: ['10-01']
files_modified:
  - docker/scripts/backup-postgres.sh
  - docker/compose.prod.yaml
  - docker/prometheus/alerts/backups.yml
autonomous: true

must_haves:
  truths:
    - 'Database backups run automatically daily via cron'
    - 'Backups upload to MinIO with 30-day retention'
    - 'Backup failures trigger alerts'
  artifacts:
    - path: 'docker/scripts/backup-postgres.sh'
      provides: 'PostgreSQL backup script'
      contains: 'pg_dump'
    - path: 'docker/compose.prod.yaml'
      provides: 'Backup service definition'
      contains: 'postgres_backup'
    - path: 'docker/prometheus/alerts/backups.yml'
      provides: 'Backup failure alert rules'
      contains: 'BackupAge'
  key_links:
    - from: 'docker/compose.prod.yaml'
      to: 'docker/scripts/backup-postgres.sh'
      via: 'volume mount'
      pattern: './scripts/backup-postgres.sh'
    - from: 'docker/scripts/backup-postgres.sh'
      to: 'minio/postgres-backups'
      via: 'mc CLI upload'
      pattern: 'mc cp.*postgres-backups'
---

<objective>
Implement automated PostgreSQL backup system with daily pg_dump to MinIO and 30-day retention

Purpose: Enable point-in-time recovery capability for production database
Output: Backup script, Docker service, and monitoring alerts for backup health
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-database-production-readiness/10-RESEARCH.md

# Existing infrastructure

@docker/docker-compose.yml
@docker/compose.prod.yaml
@scripts/deploy/notify.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PostgreSQL backup script</name>
  <files>
    docker/scripts/backup-postgres.sh
  </files>
  <action>
Create docker/scripts/ directory (if not exists) and backup-postgres.sh:

```bash
#!/bin/bash
# PostgreSQL Backup Script
# Runs daily via cron, uploads to MinIO, maintains 30-day retention
#
# Environment variables required:
# - POSTGRES_HOST, POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB
# - MINIO_ENDPOINT, MINIO_ACCESS_KEY, MINIO_SECRET_KEY
# - BACKUP_WEBHOOK_URL (optional, for failure notifications)

set -e

# Configuration
BACKUP_DATE=$(date +%Y-%m-%d_%H-%M-%S)
BACKUP_FILE="freshtrack_${BACKUP_DATE}.sql.gz"
BACKUP_PATH="/tmp/${BACKUP_FILE}"
MINIO_BUCKET="postgres-backups"
RETENTION_DAYS=${RETENTION_DAYS:-30}

# Logging
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

notify_failure() {
    local message="$1"
    log "ERROR: $message"

    if [ -n "${BACKUP_WEBHOOK_URL}" ]; then
        curl -s -X POST "${BACKUP_WEBHOOK_URL}" \
            -H "Content-Type: application/json" \
            -d "{\"text\": \"[BACKUP FAILURE] ${message}\"}" \
            || log "Failed to send notification"
    fi
    exit 1
}

# Validate required environment variables
for var in POSTGRES_HOST POSTGRES_USER POSTGRES_PASSWORD POSTGRES_DB MINIO_ENDPOINT MINIO_ACCESS_KEY MINIO_SECRET_KEY; do
    if [ -z "${!var}" ]; then
        notify_failure "Required environment variable ${var} is not set"
    fi
done

log "Starting backup of ${POSTGRES_DB}..."

# Set password for pg_dump
export PGPASSWORD="${POSTGRES_PASSWORD}"

# Create backup with custom format (compressed)
log "Running pg_dump..."
pg_dump -h "${POSTGRES_HOST}" -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -Fc > "${BACKUP_PATH}.tmp" \
    || notify_failure "pg_dump failed"

# Verify backup file is not empty
if [ ! -s "${BACKUP_PATH}.tmp" ]; then
    rm -f "${BACKUP_PATH}.tmp"
    notify_failure "Backup file is empty"
fi

# Rename to final name (atomic operation)
mv "${BACKUP_PATH}.tmp" "${BACKUP_PATH}"
BACKUP_SIZE=$(du -h "${BACKUP_PATH}" | cut -f1)
log "Backup created: ${BACKUP_FILE} (${BACKUP_SIZE})"

# Configure MinIO client
log "Configuring MinIO client..."
mc alias set minio "${MINIO_ENDPOINT}" "${MINIO_ACCESS_KEY}" "${MINIO_SECRET_KEY}" --api S3v4 \
    || notify_failure "Failed to configure MinIO client"

# Create bucket if not exists
mc mb -p "minio/${MINIO_BUCKET}" 2>/dev/null || true

# Upload backup
log "Uploading to MinIO..."
mc cp "${BACKUP_PATH}" "minio/${MINIO_BUCKET}/${BACKUP_FILE}" \
    || notify_failure "Failed to upload backup to MinIO"

# Verify upload
mc stat "minio/${MINIO_BUCKET}/${BACKUP_FILE}" > /dev/null \
    || notify_failure "Backup verification failed - file not found in MinIO"

log "Backup uploaded successfully"

# Cleanup local file
rm -f "${BACKUP_PATH}"

# Delete old backups (older than retention period)
log "Cleaning up backups older than ${RETENTION_DAYS} days..."
CUTOFF_DATE=$(date -d "${RETENTION_DAYS} days ago" +%Y-%m-%d)

# List backups and filter by date in filename
mc ls "minio/${MINIO_BUCKET}/" --json 2>/dev/null | while read -r line; do
    OBJECT_NAME=$(echo "$line" | jq -r '.key // empty')

    # Skip if no object name
    [ -z "$OBJECT_NAME" ] && continue

    # Extract date from filename (freshtrack_YYYY-MM-DD_HH-MM-SS.sql.gz)
    BACKUP_DATE_STR=$(echo "$OBJECT_NAME" | grep -oP '\d{4}-\d{2}-\d{2}' | head -1)

    # Skip if can't parse date
    [ -z "$BACKUP_DATE_STR" ] && continue

    # Compare dates
    if [[ "$BACKUP_DATE_STR" < "$CUTOFF_DATE" ]]; then
        log "Deleting old backup: ${OBJECT_NAME}"
        mc rm "minio/${MINIO_BUCKET}/${OBJECT_NAME}" 2>/dev/null || true
    fi
done

# Create timestamp file for monitoring
TIMESTAMP_FILE="/tmp/last_backup_timestamp"
date +%s > "${TIMESTAMP_FILE}"

log "Backup completed successfully: ${BACKUP_FILE}"
```

Make the script executable:

```bash
chmod +x docker/scripts/backup-postgres.sh
```

  </action>
  <verify>
    ls -la docker/scripts/backup-postgres.sh
    head -50 docker/scripts/backup-postgres.sh
    grep "pg_dump" docker/scripts/backup-postgres.sh
    grep "mc cp" docker/scripts/backup-postgres.sh
    grep "RETENTION_DAYS" docker/scripts/backup-postgres.sh
  </verify>
  <done>
    docker/scripts/backup-postgres.sh exists and is executable
    Script includes pg_dump, MinIO upload, and 30-day retention cleanup
  </done>
</task>

<task type="auto">
  <name>Task 2: Add backup service to Docker Compose and create backup alerts</name>
  <files>
    docker/compose.prod.yaml
    docker/prometheus/alerts/backups.yml
  </files>
  <action>
1. **Add postgres_backup service to docker/compose.prod.yaml**:

```yaml
# PostgreSQL Backup Service
postgres_backup:
  image: postgres:15-alpine
  container_name: freshtrack-postgres-backup
  entrypoint: ['/bin/sh', '-c']
  command:
    - |
      # Install dependencies
      apk add --no-cache curl jq

      # Install MinIO client
      wget -q https://dl.min.io/client/mc/release/linux-amd64/mc -O /usr/local/bin/mc
      chmod +x /usr/local/bin/mc

      # Run backup script and then start cron
      echo "0 2 * * * /scripts/backup-postgres.sh >> /var/log/backup.log 2>&1" | crontab -

      # Run initial backup
      /scripts/backup-postgres.sh

      # Keep container running with cron
      crond -f -l 2
  environment:
    POSTGRES_HOST: postgres
    POSTGRES_USER: ${POSTGRES_USER:-freshtrack}
    POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    POSTGRES_DB: ${POSTGRES_DB:-freshtrack}
    MINIO_ENDPOINT: http://minio:9000
    MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
    MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
    RETENTION_DAYS: '30'
    BACKUP_WEBHOOK_URL: ${DEPLOY_WEBHOOK_URL:-}
  volumes:
    - ./scripts/backup-postgres.sh:/scripts/backup-postgres.sh:ro
    - backup_logs:/var/log
  depends_on:
    postgres:
      condition: service_healthy
    minio:
      condition: service_healthy
  deploy:
    resources:
      limits:
        cpus: '0.5'
        memory: 512M
      reservations:
        cpus: '0.25'
        memory: 256M
    restart_policy:
      condition: on-failure
      delay: 5s
      max_attempts: 3
      window: 120s
  logging:
    driver: loki
    options:
      loki-url: 'http://loki:3100/loki/api/v1/push'
      loki-batch-size: '400'
      loki-retries: '3'
      loki-external-labels: 'service={{.Name}},environment=production'
```

Also add the backup_logs volume:

```yaml
volumes:
  # ... existing volumes ...
  backup_logs:
    name: freshtrack_backup_logs
```

2. **Create docker/prometheus/alerts/backups.yml**:

```yaml
groups:
  - name: database_backups
    rules:
      # No backup in the last 25 hours (allowing for 1-hour backup duration)
      - alert: BackupAgeTooOld
        expr: time() - (node_filesystem_files_free{mountpoint="/tmp"} * 0 + time()) > 90000
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: 'No recent database backup detected'
          description: 'Database backup may have failed. Last successful backup is over 25 hours old.'

      # Backup container not running
      - alert: BackupContainerDown
        expr: absent(container_last_seen{name="freshtrack-postgres-backup"})
        for: 10m
        labels:
          severity: critical
        annotations:
          summary: 'Backup container is not running'
          description: 'The postgres_backup container is not running. Database backups will not occur.'

      # Backup storage usage high (MinIO bucket)
      - alert: BackupStorageHigh
        expr: minio_bucket_usage_object_total{bucket="postgres-backups"} > 100
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: 'Backup storage growing beyond expected'
          description: 'More than 100 backup files in MinIO bucket. Check retention policy.'
```

Note: The BackupAgeTooOld alert is a placeholder. In production, you would push a custom metric from the backup script or use a file_sd target that reads from the timestamp file.
</action>
<verify>
grep -A30 "postgres_backup:" docker/compose.prod.yaml
grep "backup_logs:" docker/compose.prod.yaml
ls -la docker/prometheus/alerts/backups.yml
cat docker/prometheus/alerts/backups.yml | grep "BackupContainerDown"
docker compose -f docker/docker-compose.yml -f docker/compose.prod.yaml config --quiet && echo "Compose config valid"
</verify>
<done>
postgres_backup service added to compose.prod.yaml
backup_logs volume defined
Backup alert rules created in docker/prometheus/alerts/backups.yml
Compose configuration validates
</done>
</task>

</tasks>

<verification>
- [ ] docker/scripts/backup-postgres.sh exists and is executable
- [ ] Script includes pg_dump with custom format
- [ ] Script uploads to MinIO postgres-backups bucket
- [ ] Script implements 30-day retention cleanup
- [ ] postgres_backup service in compose.prod.yaml
- [ ] backup_logs volume defined
- [ ] docker/prometheus/alerts/backups.yml exists
- [ ] `docker compose -f docker/docker-compose.yml -f docker/compose.prod.yaml config --quiet` passes
</verification>

<success_criteria>
Automated backup system configured with daily pg_dump to MinIO, 30-day retention, and Prometheus alerting for backup failures
</success_criteria>

<output>
After completion, create `.planning/phases/10-database-production-readiness/10-03-SUMMARY.md`
</output>
