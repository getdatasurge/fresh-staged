---
phase: 07-production-deployment-cutover
plan: 05
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - compose.production.yaml
  - docs/CUTOVER_CHECKLIST.md
  - docs/USER_NOTICE_TEMPLATE.md
  - docs/PRODUCTION_DEPLOYMENT.md
autonomous: true

must_haves:
  truths:
    - "Uptime Kuma provides status page at status.freshtrackpro.com"
    - "Cutover checklist covers all steps from T-48h to T+7d"
    - "User notice template explains what to expect during cutover"
    - "Production deployment documentation complete"
  artifacts:
    - path: "docs/CUTOVER_CHECKLIST.md"
      provides: "Step-by-step cutover procedure"
      contains: "T-48h"
    - path: "docs/USER_NOTICE_TEMPLATE.md"
      provides: "User communication template"
      contains: "password reset"
    - path: "docs/PRODUCTION_DEPLOYMENT.md"
      provides: "Complete deployment documentation"
      contains: "Prerequisites"
  key_links:
    - from: "compose.production.yaml"
      to: "docker/uptime-kuma/"
      via: "service definition"
      pattern: "uptime-kuma"
---

<objective>
Add Uptime Kuma status page and create comprehensive documentation for cutover, user communication, and production deployment.

Purpose: Provide system status visibility for users and operators, document the complete cutover procedure.
Output: Status page service, cutover checklist, user notice templates, deployment documentation.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/07-production-deployment-cutover/07-CONTEXT.md
@.planning/phases/07-production-deployment-cutover/07-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Uptime Kuma status page to compose.production.yaml</name>
  <files>compose.production.yaml</files>
  <action>
Add Uptime Kuma service to compose.production.yaml:

```yaml
  # ===========================================
  # Status Page (Uptime Kuma)
  # ===========================================
  uptime-kuma:
    image: louislam/uptime-kuma:1
    container_name: frostguard-uptime-kuma
    volumes:
      - uptime_kuma_data:/app/data
    ports:
      - "127.0.0.1:3002:3001"
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
      restart_policy:
        condition: any
        delay: 5s
    restart: unless-stopped
```

Add volume:
```yaml
volumes:
  uptime_kuma_data:
    name: frostguard_uptime_kuma_data
```

This provides:
- Self-hosted status page
- 20+ notification channels
- SSL certificate monitoring
- Response time tracking
- Public status page for users
  </action>
  <verify>grep -A10 "uptime-kuma:" compose.production.yaml shows service definition</verify>
  <done>Uptime Kuma service added to compose.production.yaml</done>
</task>

<task type="auto">
  <name>Task 2: Create comprehensive cutover checklist</name>
  <files>docs/CUTOVER_CHECKLIST.md</files>
  <action>
Create docs/CUTOVER_CHECKLIST.md:

```markdown
# FreshTrack Pro Cutover Checklist

This document provides the complete cutover procedure from Supabase to the self-hosted FreshTrack Pro system.

## Overview

- **Strategy:** Freeze + Backfill (not dual-write)
- **Downtime:** Brief DNS propagation window (typically 1-4 hours)
- **Rollback Window:** 7 days post-cutover

## Prerequisites

Before beginning cutover:

- [ ] All Phase 1-6 complete (local dev, auth, API, sensors, frontend, migration scripts)
- [ ] Staging rehearsal completed successfully
- [ ] Production infrastructure provisioned (Droplet, managed PostgreSQL)
- [ ] Domain DNS access available
- [ ] Secrets generated and stored in `secrets/` directory
- [ ] Monitoring dashboards configured in Grafana
- [ ] Status page (Uptime Kuma) configured

## T-48h: Preparation

### DNS TTL Lowering
- [ ] Log in to DNS provider
- [ ] Lower TTL for freshtrackpro.com A record to 60 seconds
- [ ] Lower TTL for api.freshtrackpro.com to 60 seconds
- [ ] Lower TTL for any other subdomains
- [ ] Verify TTL change: \`dig +noall +answer freshtrackpro.com\`

### User Communication
- [ ] Send advance notice email (use template in docs/USER_NOTICE_TEMPLATE.md)
- [ ] Post notice on current status page/dashboard
- [ ] Notify support team of cutover timing

### Final Staging Verification
- [ ] Run full deployment on staging
- [ ] Execute complete test scenario (login, view data, create alert)
- [ ] Verify migration scripts work with production-like data
- [ ] Test rollback procedure on staging

## T-24h: Final Preparation

### System Verification
- [ ] Run \`./scripts/health-check.sh\` on production server
- [ ] Verify all secrets are in place
- [ ] Verify managed PostgreSQL is accessible
- [ ] Test Caddy SSL certificate provisioning (dry run)

### Backup
- [ ] Create final Supabase database backup
- [ ] Download backup to local storage
- [ ] Verify backup integrity (can restore)

### Communication
- [ ] Confirm support team availability during cutover window
- [ ] Prepare incident response contacts

## T-0: Cutover Execution

### Step 1: Freeze Supabase (T+0:00)
- [ ] Set Supabase project to read-only or pause writes
- [ ] Note exact freeze timestamp: ___________
- [ ] Verify no new data being written

### Step 2: Export Data (T+0:05)
- [ ] Run export script: \`pnpm --prefix scripts/migration run export\`
- [ ] Verify export completed: Check \`migration-data/metadata.json\`
- [ ] Note row counts for key tables:
  - organizations: _____
  - sensor_readings: _____
  - alerts: _____

### Step 3: Migrate Users (T+0:15)
- [ ] Run user migration: \`pnpm --prefix scripts/migration run migrate-users\`
- [ ] Verify user mapping file created
- [ ] Note users migrated: _____

### Step 4: Import Data (T+0:30)
- [ ] Run import script: \`pnpm --prefix scripts/migration run import\`
- [ ] Monitor for errors
- [ ] Note completion time: ___________

### Step 5: Verify Migration (T+1:00)
- [ ] Run verification: \`pnpm --prefix scripts/migration run verify\`
- [ ] All tables pass row count check: [ ]
- [ ] Checksums match (where applicable): [ ]
- [ ] Manual spot-check of 3-5 records: [ ]

### Step 6: Deploy Application (T+1:30)
- [ ] Run deployment: \`./scripts/deploy.sh\`
- [ ] Wait for health checks to pass
- [ ] Verify backend responds: \`curl https://api.freshtrackpro.com/health\`

### Step 7: Update DNS (T+2:00)
- [ ] Update A record for freshtrackpro.com to new IP: ___________
- [ ] Update A record for api.freshtrackpro.com
- [ ] Update A record for status.freshtrackpro.com
- [ ] Verify DNS propagation: \`dig +short freshtrackpro.com\`

### Step 8: Validate Cutover (T+2:15)
- [ ] Access https://freshtrackpro.com - loads correctly
- [ ] Login works with existing user (prompts for password reset)
- [ ] Historical data visible in dashboard
- [ ] Create test alert - notification received
- [ ] Sensor data flowing (if test sensors available)

## T+0 to T+2h: Critical Monitoring

### Every 15 Minutes
- [ ] Check Grafana dashboards for errors
- [ ] Check Uptime Kuma for service health
- [ ] Monitor CPU/memory usage
- [ ] Check error logs: \`docker compose logs backend --tail 100\`

### User Feedback
- [ ] Monitor support email for issues
- [ ] Check for login problems
- [ ] Check for data access issues

### Rollback Triggers
If any of these occur, consider immediate rollback:
- [ ] Sensor data not being captured for >15 minutes
- [ ] Alert system not triggering on test excursion
- [ ] >10% of login attempts failing
- [ ] Database connection errors

## T+2h to T+24h: Stabilization

- [ ] Continue monitoring dashboards
- [ ] Address any non-critical issues
- [ ] Document any problems encountered
- [ ] Verify sensor data accumulating correctly

## T+24h: First Day Review

- [ ] Review error logs from past 24 hours
- [ ] Check data reconciliation (row counts)
- [ ] Verify all scheduled jobs running
- [ ] Send "cutover successful" communication to users

## T+48h to T+7d: Rollback Window

- [ ] Keep Supabase in read-only mode (available for rollback)
- [ ] Daily: Check data reconciliation
- [ ] Daily: Review error rates
- [ ] Daily: Confirm sensor data flowing

## T+7d: Cutover Complete

- [ ] Raise DNS TTL back to normal (3600s)
- [ ] Final reconciliation check
- [ ] Archive Supabase data (optional)
- [ ] Decommission Supabase project (or keep for reference)
- [ ] Send "migration complete" communication
- [ ] Update documentation (remove Supabase references)
- [ ] Celebrate! ðŸŽ‰

## Rollback Procedure

If rollback needed, see \`./scripts/rollback.sh\` for automated procedure.

Quick reference:
1. Stop new system: \`docker compose stop backend caddy\`
2. Export post-cutover data: \`./scripts/rollback.sh\` handles this
3. Update DNS back to Supabase IP
4. Re-enable Supabase writes
5. Notify users of rollback

## Emergency Contacts

| Role | Name | Contact |
|------|------|---------|
| On-Call Engineer | _______ | _______ |
| DBA | _______ | _______ |
| Infrastructure | _______ | _______ |

---
*Last Updated: 2026-01-23*
```
  </action>
  <verify>cat docs/CUTOVER_CHECKLIST.md | grep "T-48h" shows timeline present</verify>
  <done>Comprehensive cutover checklist created with T-48h to T+7d timeline</done>
</task>

<task type="auto">
  <name>Task 3: Create user notice template and production deployment docs</name>
  <files>docs/USER_NOTICE_TEMPLATE.md, docs/PRODUCTION_DEPLOYMENT.md</files>
  <action>
Create docs/USER_NOTICE_TEMPLATE.md:

```markdown
# User Communication Templates

## 24-48 Hours Before Cutover

**Subject:** FreshTrack Pro System Update - Action Required

---

Dear FreshTrack Pro User,

We are upgrading the FreshTrack Pro infrastructure to improve reliability, performance, and security.

**When:** [DATE/TIME]
**Expected Duration:** 1-2 hours

### What to Expect

- **Brief Interruption:** The system may be briefly unavailable during the update window
- **Password Reset Required:** You will be prompted to reset your password on first login after the update
- **Data Preserved:** All your historical temperature data and configurations will be preserved

### During the Update

- Sensors will continue collecting data
- If you cannot access the dashboard, please wait and try again in 30 minutes
- Check our status page for real-time updates: https://status.freshtrackpro.com

### After the Update

1. Visit https://freshtrackpro.com
2. Click "Forgot Password" to set a new password
3. Log in with your email and new password
4. Verify your dashboard shows your expected data

### Questions?

- Check our status page: https://status.freshtrackpro.com
- Email support: support@freshtrackpro.com
- View release notes: [LINK]

Thank you for your patience as we improve FreshTrack Pro!

Best regards,
The FreshTrack Pro Team

---

## Post-Cutover Confirmation

**Subject:** FreshTrack Pro Update Complete

---

Dear FreshTrack Pro User,

The FreshTrack Pro system update has been completed successfully.

### What's Changed

- Improved system reliability and performance
- Enhanced security measures
- Better monitoring and support capabilities

### Action Required

**Please reset your password:**
1. Visit https://freshtrackpro.com
2. Click "Forgot Password"
3. Check your email for the reset link
4. Create a new secure password

### Your Data

All your historical temperature data, alerts, and configurations have been preserved. If you notice any discrepancies, please contact support immediately.

### Need Help?

- Status Page: https://status.freshtrackpro.com
- Support Email: support@freshtrackpro.com
- Documentation: [LINK]

Thank you for using FreshTrack Pro!

Best regards,
The FreshTrack Pro Team

---

## Rollback Notice (If Needed)

**Subject:** FreshTrack Pro Update - Temporary Rollback

---

Dear FreshTrack Pro User,

We encountered an issue during the FreshTrack Pro system update and have temporarily reverted to the previous system.

### What This Means

- The system is fully operational on the previous infrastructure
- Your existing login credentials continue to work (no password reset needed)
- All data remains intact

### Next Steps

We are investigating the issue and will reschedule the update. We will notify you before the next attempt.

### Questions?

Please contact support@freshtrackpro.com with any concerns.

We apologize for any inconvenience.

Best regards,
The FreshTrack Pro Team
```

Create docs/PRODUCTION_DEPLOYMENT.md:

```markdown
# FreshTrack Pro Production Deployment Guide

This guide covers deploying FreshTrack Pro to production infrastructure.

## Prerequisites

### Infrastructure

1. **DigitalOcean Droplet** (or equivalent):
   - Ubuntu 24.04 LTS
   - 2-4 GB RAM minimum
   - 50 GB SSD storage
   - Docker and Docker Compose installed

2. **Managed PostgreSQL**:
   - DigitalOcean Managed PostgreSQL recommended
   - PostgreSQL 15+
   - SSL connection required
   - Basic plan sufficient for 50-500 users

3. **Domain Configuration**:
   - Primary domain (e.g., freshtrackpro.com)
   - API subdomain (e.g., api.freshtrackpro.com)
   - Monitoring subdomain (e.g., monitoring.freshtrackpro.com)
   - Status subdomain (e.g., status.freshtrackpro.com)

### External Services

- **Stack Auth** account with project configured
- **DNS Provider** access for domain management

## Initial Server Setup

```bash
# SSH into server
ssh root@your-server-ip

# Update system
apt update && apt upgrade -y

# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Install Docker Compose plugin
apt install docker-compose-plugin

# Create deploy user
adduser deploy
usermod -aG docker deploy

# Clone repository
su - deploy
git clone https://github.com/your-org/freshtrack-pro.git
cd freshtrack-pro
```

## Configuration

### 1. Create Secrets

```bash
# Create secrets directory
mkdir -p secrets
chmod 700 secrets

# Generate secrets
openssl rand -base64 32 > secrets/jwt_secret.txt
openssl rand -base64 32 > secrets/grafana_password.txt

# Add managed database password
echo "your-db-password" > secrets/postgres_password.txt

# Add Stack Auth secret
echo "your-stack-auth-secret" > secrets/stack_auth_secret.txt

# Add MinIO credentials
echo "minio-admin" > secrets/minio_user.txt
openssl rand -base64 32 > secrets/minio_password.txt

# Secure permissions
chmod 600 secrets/*.txt
```

### 2. Create Environment File

```bash
cp .env.production.example .env.production

# Edit with your values
nano .env.production
```

Key settings:
- \`DOMAIN=freshtrackpro.com\`
- \`DATABASE_URL=postgresql://...\`
- \`STACK_AUTH_PROJECT_ID=...\`

### 3. Configure Caddy

Update \`docker/caddy/Caddyfile\`:
- Set admin email for Let's Encrypt
- Verify domain configuration

### 4. Configure Uptime Kuma

After first deployment, access Uptime Kuma at \`http://localhost:3002\`:
1. Create admin account
2. Add monitors for:
   - Backend health: \`https://api.freshtrackpro.com/health\`
   - Frontend: \`https://freshtrackpro.com\`
   - Database connection (via backend health)
3. Configure notification channels

## Deployment

### First Deployment

```bash
# Run pre-flight checks
./scripts/health-check.sh

# Deploy
./scripts/deploy.sh
```

### Subsequent Deployments

```bash
# Pull latest code
git pull

# Deploy (skips some checks if previously passed)
./scripts/deploy.sh
```

### Viewing Logs

```bash
# All services
docker compose -f docker-compose.yml -f compose.production.yaml logs -f

# Specific service
docker compose -f docker-compose.yml -f compose.production.yaml logs -f backend

# Last 100 lines
docker compose -f docker-compose.yml -f compose.production.yaml logs --tail 100 backend
```

## Monitoring

### Grafana Dashboards

Access at \`https://monitoring.freshtrackpro.com\`

Default dashboards:
- **FreshTrack Overview**: CPU, memory, service health, logs
- **Node Exporter**: Detailed host metrics

### Uptime Kuma

Access at \`https://status.freshtrackpro.com\`

Public status page shows:
- Service availability
- Response times
- Incident history

### Manual Checks

```bash
# Container status
docker compose -f docker-compose.yml -f compose.production.yaml ps

# Resource usage
docker stats

# Health endpoint
curl https://api.freshtrackpro.com/health
```

## Maintenance

### Database Backups

Managed PostgreSQL handles automated backups. For manual backup:

```bash
docker compose -f docker-compose.yml -f compose.production.yaml \
  exec postgres pg_dump -U frostguard frostguard > backup.sql
```

### Log Rotation

Docker handles log rotation. Check \`/etc/docker/daemon.json\` for settings.

### Updates

```bash
# Check for security updates
apt list --upgradable

# Update Docker images
docker compose -f docker-compose.yml -f compose.production.yaml pull
./scripts/deploy.sh
```

## Troubleshooting

### Container Won't Start

```bash
# Check logs
docker compose -f docker-compose.yml -f compose.production.yaml logs backend

# Check health
docker inspect --format='{{.State.Health.Status}}' frostguard-backend
```

### Database Connection Issues

```bash
# Test connection
docker compose -f docker-compose.yml -f compose.production.yaml \
  exec backend node -e "require('./dist/db').db.execute('SELECT 1')"
```

### SSL Certificate Issues

```bash
# Check Caddy logs
docker compose -f docker-compose.yml -f compose.production.yaml logs caddy

# Force certificate renewal
docker compose -f docker-compose.yml -f compose.production.yaml \
  exec caddy caddy reload --config /etc/caddy/Caddyfile
```

## Rollback

If issues occur, use the rollback script:

```bash
./scripts/rollback.sh
```

See \`docs/CUTOVER_CHECKLIST.md\` for detailed rollback procedure.

---
*Last Updated: 2026-01-23*
```
  </action>
  <verify>ls docs/USER_NOTICE_TEMPLATE.md docs/PRODUCTION_DEPLOYMENT.md shows both files exist</verify>
  <done>User notice templates and production deployment documentation created</done>
</task>

</tasks>

<verification>
Run all verification commands:
1. `grep "uptime-kuma:" compose.production.yaml` - Uptime Kuma service added
2. `grep "T-48h" docs/CUTOVER_CHECKLIST.md` - Checklist has timeline
3. `grep "password reset" docs/USER_NOTICE_TEMPLATE.md` - User notice mentions password reset
4. `grep "Prerequisites" docs/PRODUCTION_DEPLOYMENT.md` - Deployment docs complete
5. `ls docs/*.md | wc -l` - Documentation files created
</verification>

<success_criteria>
- Uptime Kuma service added to compose.production.yaml
- Cutover checklist covers T-48h through T+7d
- User notice template includes password reset messaging
- Production deployment documentation is comprehensive
- All documentation is actionable and specific
</success_criteria>

<output>
After completion, create `.planning/phases/07-production-deployment-cutover/07-05-SUMMARY.md`
</output>
