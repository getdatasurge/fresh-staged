---
phase: 06-data-migration-scripts
plan: 05
type: execute
wave: 4
depends_on: ['06-02', '06-04']
files_modified:
  - scripts/migration/lib/checksum.ts
  - scripts/migration/verify.ts
autonomous: true

must_haves:
  truths:
    - 'Verification script compares source and target databases'
    - 'Row counts verified for all tables'
    - 'Checksums match between source and target'
    - 'Verification report generated with pass/fail status'
  artifacts:
    - path: 'scripts/migration/verify.ts'
      provides: 'Main verification script'
      exports: ['main']
    - path: 'scripts/migration/lib/checksum.ts'
      provides: 'Checksum computation utilities'
      exports: ['computeTableChecksum', 'getTableRowCount']
  key_links:
    - from: 'scripts/migration/verify.ts'
      to: 'scripts/migration/lib/supabase-client.ts'
      via: 'import for source'
      pattern: 'supabasePool'
    - from: 'scripts/migration/verify.ts'
      to: 'scripts/migration/lib/new-db-client.ts'
      via: 'import for target'
      pattern: 'newDbPool'
---

<objective>
Create verification script to confirm data integrity after migration.

Purpose: Verify that all data migrated correctly by comparing row counts and checksums between Supabase (source) and new PostgreSQL (target). This is the final gate before cutting over to the new system.

Output:

- scripts/migration/verify.ts - Main verification CLI
- scripts/migration/lib/checksum.ts - Checksum utilities
- migration-data/verification-report.json (generated at runtime)
  </objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-data-migration-scripts/06-CONTEXT.md
@.planning/phases/06-data-migration-scripts/06-RESEARCH.md
@.planning/phases/06-data-migration-scripts/06-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create checksum computation utilities</name>
  <files>
    scripts/migration/lib/checksum.ts
  </files>
  <action>
Create checksum.ts with utilities for data integrity verification:

1. getTableRowCount(pool, tableName):

   ```typescript
   async function getTableRowCount(pool: Pool, tableName: string): Promise<number> {
     const result = await pool.query(`SELECT COUNT(*) FROM ${tableName}`);
     return parseInt(result.rows[0].count, 10);
   }
   ```

2. computeTableChecksum(pool, tableName):
   - Use PostgreSQL MD5 aggregation for deterministic checksum
   - Sort rows to ensure consistent ordering

   ```typescript
   async function computeTableChecksum(pool: Pool, tableName: string): Promise<string | null> {
     try {
       // Get deterministic checksum of all row data
       const result = await pool.query(`
         SELECT md5(string_agg(row_hash, '' ORDER BY row_hash)) as checksum
         FROM (
           SELECT md5(CAST(t AS text)) as row_hash
           FROM ${tableName} t
         ) hashes
       `);
       return result.rows[0].checksum;
     } catch (err) {
       // Table might have columns that don't cast to text well
       logger.warn(
         { tableName, err },
         'Checksum computation failed, falling back to row count only',
       );
       return null;
     }
   }
   ```

3. compareTableStats(sourcePool, targetPool, tableName):

   ```typescript
   interface TableComparison {
     tableName: string;
     sourceRowCount: number;
     targetRowCount: number;
     rowCountMatch: boolean;
     sourceChecksum: string | null;
     targetChecksum: string | null;
     checksumMatch: boolean | null; // null if checksum couldn't be computed
     status: 'pass' | 'fail' | 'warn';
   }
   ```

4. Handle edge cases:
   - Tables with JSONB columns may need special handling for checksum
   - Timestamps should be consistent (both in UTC)
   - User ID columns will differ (expected - don't include in checksum)

5. For tables with user ID columns, compute checksum EXCLUDING those columns:
   ```typescript
   async function computeChecksumExcludingColumns(
     pool: Pool,
     tableName: string,
     excludeColumns: string[],
   ): Promise<string | null>;
   ```
     </action>
     <verify>
   Test checksum computation on a known table, verify consistent results across multiple runs.
     </verify>
     <done>
   Checksum utilities compute deterministic hashes that match for identical data.
     </done>
   </task>

<task type="auto">
  <name>Task 2: Create main verification script</name>
  <files>
    scripts/migration/verify.ts
  </files>
  <action>
Create verify.ts as the main verification CLI:

1. CLI options with commander:
   - --output (default: ./migration-data/verification-report.json)
   - --table (optional, verify single table)
   - --skip-checksum (only verify row counts for speed)
   - --fail-fast (stop on first mismatch)

2. Main verification flow:

   ```typescript
   async function main() {
     const supabasePool = await getSupabaseClient();
     const newDbPool = await getNewDbClient();
     const opts = program.opts();

     const tables = getTableImportOrder();
     const results: TableComparison[] = [];
     let allPassed = true;

     for (const table of tables) {
       logger.info({ table }, 'Verifying table...');

       try {
         // Get row counts
         const sourceRowCount = await getTableRowCount(supabasePool, table);
         const targetRowCount = await getTableRowCount(newDbPool, table);
         const rowCountMatch = sourceRowCount === targetRowCount;

         // Get checksums (if not skipped)
         let sourceChecksum: string | null = null;
         let targetChecksum: string | null = null;
         let checksumMatch: boolean | null = null;

         if (!opts.skipChecksum) {
           // For tables with user IDs, exclude those columns from checksum
           if (requiresUserMapping(table)) {
             const excludeCols = getUserIdColumns(table);
             sourceChecksum = await computeChecksumExcludingColumns(
               supabasePool,
               table,
               excludeCols,
             );
             targetChecksum = await computeChecksumExcludingColumns(newDbPool, table, excludeCols);
           } else {
             sourceChecksum = await computeTableChecksum(supabasePool, table);
             targetChecksum = await computeTableChecksum(newDbPool, table);
           }

           if (sourceChecksum && targetChecksum) {
             checksumMatch = sourceChecksum === targetChecksum;
           }
         }

         // Determine status
         let status: 'pass' | 'fail' | 'warn' = 'pass';
         if (!rowCountMatch) status = 'fail';
         if (checksumMatch === false) status = 'fail';
         if (checksumMatch === null && !opts.skipChecksum) status = 'warn';

         const result: TableComparison = {
           tableName: table,
           sourceRowCount,
           targetRowCount,
           rowCountMatch,
           sourceChecksum,
           targetChecksum,
           checksumMatch,
           status,
         };

         results.push(result);

         if (status === 'pass') {
           logger.info({ table, rowCount: sourceRowCount }, 'PASS');
         } else if (status === 'warn') {
           logger.warn({ table, result }, 'WARN - checksum not computed');
         } else {
           logger.error({ table, result }, 'FAIL');
           allPassed = false;
           if (opts.failFast) break;
         }
       } catch (err) {
         logger.error({ err, table }, 'Verification error');
         allPassed = false;
         if (opts.failFast) break;
       }
     }

     // Write report
     const report = {
       verifiedAt: new Date().toISOString(),
       allPassed,
       summary: {
         total: results.length,
         passed: results.filter((r) => r.status === 'pass').length,
         warned: results.filter((r) => r.status === 'warn').length,
         failed: results.filter((r) => r.status === 'fail').length,
       },
       results,
     };

     await fs.writeFile(opts.output, JSON.stringify(report, null, 2));

     // Final summary
     if (allPassed) {
       logger.info('VERIFICATION PASSED - All tables match');
     } else {
       logger.error('VERIFICATION FAILED - See report for details');
       process.exit(1);
     }
   }
   ```

3. Console output formatting:
   - Use table format for summary
   - Color-code pass/fail/warn
   - Show progress during verification
     </action>
     <verify>
     Run `pnpm exec tsx verify.ts --help` to verify CLI. Test with --skip-checksum if DB access limited.
     </verify>
     <done>
     Verification script compares source and target databases and generates detailed report.
     </done>
     </task>

</tasks>

<verification>
1. `pnpm exec tsx verify.ts --help` shows CLI options
2. Row counts compared for all tables
3. Checksums computed and compared (excluding user ID columns)
4. Report file generated with pass/fail/warn status
5. Exit code 1 if any table fails verification
6. --fail-fast stops on first mismatch
</verification>

<success_criteria>

- Verification script connects to both databases
- Row counts match between source and target
- Checksums match (excluding user ID columns which are expected to differ)
- Clear report generated with pass/fail status per table
- Overall pass/fail determination based on all tables
  </success_criteria>

<output>
After completion, create `.planning/phases/06-data-migration-scripts/06-05-SUMMARY.md`
</output>
